<div itemscope itemtype="http://developers.google.com/ReferenceObject">
<meta itemprop="name" content="tfa.layers" />
<meta itemprop="path" content="Stable" />
</div>

# Module: tfa.layers


<table class="tfo-notebook-buttons tfo-api" align="left">

<td>
  <a target="_blank" href="https://github.com/tensorflow/addons/tree/r0.7/tensorflow_addons/layers/__init__.py">
    <img src="https://www.tensorflow.org/images/GitHub-Mark-32px.png" />
    View source on GitHub
  </a>
</td></table>



Additional layers that conform to Keras API.



## Modules

[`gelu`](../tfa/layers/gelu.md) module: Implements GELU activation.

[`maxout`](../tfa/layers/maxout.md) module: Implementing Maxout layer.

[`normalizations`](../tfa/layers/normalizations.md) module

[`optical_flow`](../tfa/layers/optical_flow.md) module: Tensorflow op performing correlation cost operation.

[`poincare`](../tfa/layers/poincare.md) module: Implementing PoincareNormalize layer.

[`sparsemax`](../tfa/layers/sparsemax.md) module

[`wrappers`](../tfa/layers/wrappers.md) module

## Classes

[`class CorrelationCost`](../tfa/layers/CorrelationCost.md): Correlation Cost Layer.

[`class GELU`](../tfa/layers/GELU.md): Gaussian Error Linear Unit.

[`class GroupNormalization`](../tfa/layers/GroupNormalization.md): Group normalization layer.

[`class InstanceNormalization`](../tfa/layers/InstanceNormalization.md): Instance normalization layer.

[`class Maxout`](../tfa/layers/Maxout.md): Applies Maxout to the input.

[`class PoincareNormalize`](../tfa/layers/PoincareNormalize.md): Project into the Poincare ball with norm <= 1.0 - epsilon.

[`class Sparsemax`](../tfa/layers/Sparsemax.md): Sparsemax activation function [1].

[`class WeightNormalization`](../tfa/layers/WeightNormalization.md): This wrapper reparameterizes a layer by decoupling the weight's



