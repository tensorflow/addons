{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ],
      "metadata": {
        "id": "Tce3stUlHN0L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "outputs": [],
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TensorFlow Addons Layers: CRF"
      ],
      "metadata": {
        "id": "qFdPvlXBOdUN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfa-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/addons/tutorials/layers_crf\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/addons/blob/master/docs/tutorials/layers_crf.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/addons/blob/master/docs/tutorials/layers_crf.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "      <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/addons/docs/tutorials/layers_crf.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "MfBg1C5NB3X0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "This notebook will demonstrate how to use the CRF (Conditional Random Field) layer in TensorFlow Addons."
      ],
      "metadata": {
        "id": "xHxb-dlhMIzW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "MUXex9ctTuDB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "!pip install -U tensorflow-addons"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
            "Requirement already up-to-date: tensorflow-addons in /home/howl/.local/lib/python3.8/site-packages (0.14.0)\n",
            "Requirement already satisfied, skipping upgrade: typeguard>=2.7 in /home/howl/.local/lib/python3.8/site-packages (from tensorflow-addons) (2.12.1)\n"
          ]
        }
      ],
      "metadata": {
        "id": "rEk-ibQkDNtF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-08-28 14:43:44.853120: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
            "2021-08-28 14:43:44.853136: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "/home/howl/.pyenv/versions/3.7.11/lib/python3.7/site-packages/pandas/compat/__init__.py:124: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "metadata": {
        "id": "IqR2PQG4ZaZ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the constant"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define some constants which will be used in multiple places:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "# Define constant\n",
        "VOCAB_SIZE = 100\n",
        "TAG_SIZE = 100"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Traning data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using real data sets requires a lot of code. Here we simply generate some random data for training:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "train_x = tf.random.uniform((10, 6), dtype=tf.int32, minval=1, maxval=VOCAB_SIZE)\n",
        "train_y = train_x"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-08-28 14:43:45.584023: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2021-08-28 14:43:45.610798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-08-28 14:43:45.611148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:06:00.0 name: NVIDIA GeForce GTX 1070 computeCapability: 6.1\n",
            "coreClock: 1.721GHz coreCount: 15 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s\n",
            "2021-08-28 14:43:45.611208: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
            "2021-08-28 14:43:45.611244: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\n",
            "2021-08-28 14:43:45.612015: I tenso"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "rflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2021-08-28 14:43:45.612193: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2021-08-28 14:43:45.612236: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory\n",
            "2021-08-28 14:43:45.612269: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory\n",
            "2021-08-28 14:43:45.612299: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
            "2021-08-28 14:43:45.612303: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2021-08-28 14:43:45.612799: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-08-28 14:43:45.636639: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3393610000 Hz\n",
            "2021-08-28 14:43:45.637562: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f30695dac0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2021-08-28 14:43:45.637575: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2021-08-28 14:43:45.638703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-08-28 14:43:45.638710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      \n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define our BiLSTM+CRF model by using tfa.layers.CRF layer.\n",
        "The CRF layer not only ouput the CRF decode result (`decode_sequence`), but also outupt some interal variables (`potentials`, `sequence_length` and `kernel`). We will use those internal variables for compute loss value later."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# Build the model\n",
        "def build_embedding_bilstm_crf_model(\n",
        "    vocab_size: int, embed_dims: int, lstm_unit: int, tag_size: int\n",
        ") -> tf.keras.Model:\n",
        "    x = tf.keras.layers.Input(shape=(None,), dtype=tf.int32, name=\"x\")\n",
        "    y = tf.keras.layers.Embedding(vocab_size, embed_dims, mask_zero=True)(x)\n",
        "    y = tf.keras.layers.Bidirectional(\n",
        "        tf.keras.layers.LSTM(lstm_unit, return_sequences=True)\n",
        "    )(y)\n",
        "    decode_sequence, potentials, sequence_length, kernel = tfa.layers.CRF(tag_size)(y)\n",
        "\n",
        "    return tf.keras.Model(\n",
        "        inputs=x, outputs=[decode_sequence, potentials, sequence_length, kernel]\n",
        "    )\n",
        "\n",
        "\n",
        "model = build_embedding_bilstm_crf_model(VOCAB_SIZE, 32, 8, TAG_SIZE)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "KtylpxOmceaC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the model on a single batch of data, and inspect the output:"
      ],
      "metadata": {
        "id": "pwdM2pl3RSPb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "inputs_for_inspect = train_x[:1]\n",
        "decode_sequence, potentials, sequence_length, kernel = model(inputs_for_inspect)\n",
        "\n",
        "print(inputs_for_inspect)\n",
        "print(decode_sequence)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[26 80 77 74 46 80]], shape=(1, 6), dtype=int32)\n",
            "tf.Tensor([[50 44 50 44 50 44]], shape=(1, 6), dtype=int32)\n"
          ]
        }
      ],
      "metadata": {
        "id": "mMOeXVmbdilM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define CRF loss function"
      ],
      "metadata": {
        "id": "uabQmjMtRtzs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By using the real y and some internal variables of the CRF layer. We can compute the log likelihood of real y. We use the negative of log likelihood as the loss we want to optimize."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "@tf.function\n",
        "def crf_loss_func(potentials, sequence_length, kernel, y):\n",
        "    crf_likelihood, _ = tfa.text.crf_log_likelihood(\n",
        "        potentials, y, sequence_length, kernel\n",
        "    )\n",
        "    # likelihood to loss\n",
        "    flat_crf_loss = -1 * crf_likelihood\n",
        "    crf_loss = tf.reduce_mean(flat_crf_loss)\n",
        "\n",
        "    return crf_loss"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define optimizer, metrics and train_step fucntion"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "optimizer = tf.keras.optimizers.Adam(0.1)\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
        "\n",
        "@tf.function\n",
        "def train_step(x, y):\n",
        "    with tf.GradientTape() as tape:\n",
        "        decoded_sequence, potentials, sequence_length, kernel = model(x)\n",
        "        crf_loss = crf_loss_func(potentials, sequence_length, kernel, y)\n",
        "        loss = crf_loss + tf.reduce_sum(model.losses)\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)"
      ],
      "outputs": [],
      "metadata": {
        "id": "U82B_tH2d294"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define training data"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).cache()\n"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Reset the metrics at the start of the next epoch\n",
        "    train_loss.reset_states()\n",
        "\n",
        "    for x, y in dataset.batch(10):\n",
        "        train_step(x, y)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}, \" f\"Loss: {train_loss.result()}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2021-08-28 14:43:50.012581: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:906] Skipping loop optimization for Merge node with control input: StatefulPartitionedCall/cond_1_11/branch_executed/_240\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 27.771350860595703\n",
            "Epoch 2, Loss: 25.085397720336914\n",
            "Epoch 3, Loss: 20.460519790649414\n",
            "Epoch 4, Loss: 15.814981460571289\n",
            "Epoch 5, Loss: 11.373090744018555\n",
            "Epoch 6, Loss: 7.605006217956543\n",
            "Epoch 7, Loss: 4.418956279754639\n",
            "Epoch 8, Loss: 2.2545323371887207\n",
            "Epoch 9, Loss: 1.0994850397109985\n",
            "Epoch 10, Loss: 0.541629433631897\n"
          ]
        }
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make inference"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "decoded_sequence, *_ = model.predict(inputs_for_inspect)\n",
        "\n",
        "print(inputs_for_inspect)\n",
        "print(decoded_sequence)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([[26 80 77 74 46 80]], shape=(1, 6), dtype=int32)\n",
            "[[26 80 77 74 46 80]]\n"
          ]
        }
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Tce3stUlHN0L"
      ],
      "name": "_template.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.11 64-bit ('3.7.11': pyenv)"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "interpreter": {
      "hash": "a3404df53504d9003a0360944dfd21c4c6bea3a8b28432aa46784f8d9ee98897"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}