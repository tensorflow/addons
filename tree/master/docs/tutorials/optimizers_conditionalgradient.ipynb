{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "optimizers_conditionalgradient.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkan2/addons/blob/master/tree/master/docs/tutorials/optimizers_conditionalgradient.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGUYKbJNWNgj",
        "colab_type": "text"
      },
      "source": [
        "##### Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PzPJglSWgnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5P4BEg1XYd5",
        "colab_type": "text"
      },
      "source": [
        "# TensorFlow Addons Optimizers: ConditionalGradient\n",
        "\n",
        "### TBD!!!!!! to modify the ref link\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/drive/1UT4e-BZkpdsavgLXUpsCN5KEpAB3NY_b#scrollTo=b5P4BEg1XYd5\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/pkan2/addons/blob/master/tree/master/docs/tutorials/optimizers_conditionalgradient.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Faj8luWnYNSG",
        "colab_type": "text"
      },
      "source": [
        "# Overview\n",
        "This notebook will demonstrate how to use the Conditional Graident Optimizer from the Addons package."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrDjqjY6YRYM",
        "colab_type": "text"
      },
      "source": [
        "# ConditionalGradient\n",
        "\n",
        "> Condtitional Gradient Optimizer provides an alternative method for handling regularizer in the optimization process. The implementation of this optimizer is based on the following paper:\n",
        "https://arxiv.org/pdf/1803.06453.pdf. Current implementation enforces Frobenius norm constraints on a model. The variable update rule being implemented is:\n",
        "$variable -= (1 - learning\\_rate) \\times (variable + lambda\\_ \\times \\frac{gradient}{  frobenius\\_norm(gradient) + epsilon})$, \n",
        "where, 'learning_rate' and 'lambda\\_' are the parameters that are needed to input into the model when initializing the model. And 'epsilon' is a constant, which is relatively small as compared to the norm of gradient. The purpose of 'epsilon' here is to handle the case of undefined mathematic operation to divided by zero, when the norm of gradient equals zero.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dooBaYGLYYnn",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPbEvhbCih0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0rc0\n",
        "!pip install tfa-nightly\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR0PnjrIirpJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size=64\n",
        "epochs=10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-x0WBp-IYz7x",
        "colab_type": "text"
      },
      "source": [
        "# Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KzMDUT0i1QE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(64, input_shape=(784,), activation='relu', name='dense_1'),\n",
        "    tf.keras.layers.Dense(64, activation='relu', name='dense_2'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax', name='predictions'),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGADNG3-Y7aa",
        "colab_type": "text"
      },
      "source": [
        "# Prep the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6a-kbM_i1b2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load MNIST dataset as NumPy arrays\n",
        "dataset = {}\n",
        "num_validation = 10000\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = x_train.reshape(-1, 784).astype('float32') / 255\n",
        "x_test = x_test.reshape(-1, 784).astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOlB-WqjZp1Y",
        "colab_type": "text"
      },
      "source": [
        "# Define a Custom Callback Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LCmRXUgZqyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function is to calculate the frobenius norm of the matrix of all\n",
        "# layer's weight.\n",
        "# args:\n",
        "#      m: is a list of weights param for each layers\n",
        "def frobenius_norm(m):\n",
        "    total_reduce_sum = 0\n",
        "    for i in range(len(m)):\n",
        "        total_reduce_sum = total_reduce_sum + tf.math.reduce_sum(m[i]**2)\n",
        "    norm = total_reduce_sum**0.5\n",
        "    return norm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udSvzKm4Z5Zr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CG_frobenius_norm_of_weight = []\n",
        "CG_get_weight_norm = tf.keras.callbacks.LambdaCallback(\n",
        "    on_epoch_end=lambda batch, logs: CG_frobenius_norm_of_weight.append(\n",
        "        frobenius_norm(model_1.trainable_weights).numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfhE1DfwZC1i",
        "colab_type": "text"
      },
      "source": [
        "# Train and Evaluate\n",
        "\n",
        "Simply replace typical keras optimizers with the new tfa optimizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-AMaOYEi1kK",
        "colab_type": "code",
        "outputId": "b32c2848-0428-4c50-b5f9-218f311534fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "# Compile the model\n",
        "model_1.compile(\n",
        "    optimizer=tfa.optimizers.ConditionalGradient(\n",
        "        learning_rate=0.99949, lambda_=203),  # Utilize TFA optimizer\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "history_1 = model_1.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(x_test, y_test),\n",
        "    epochs=epochs,\n",
        "    callbacks=[CG_get_weight_norm])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.3704 - accuracy: 0.8886 - val_loss: 0.2121 - val_accuracy: 0.9360\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1878 - accuracy: 0.9438 - val_loss: 0.1657 - val_accuracy: 0.9504\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1490 - accuracy: 0.9556 - val_loss: 0.1415 - val_accuracy: 0.9572\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1325 - accuracy: 0.9596 - val_loss: 0.1455 - val_accuracy: 0.9534\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1213 - accuracy: 0.9634 - val_loss: 0.1557 - val_accuracy: 0.9499\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 0.1166 - accuracy: 0.9643 - val_loss: 0.1219 - val_accuracy: 0.9618\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 67us/sample - loss: 0.1113 - accuracy: 0.9663 - val_loss: 0.1252 - val_accuracy: 0.9601\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1089 - accuracy: 0.9673 - val_loss: 0.1061 - val_accuracy: 0.9675\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 4s 68us/sample - loss: 0.1061 - accuracy: 0.9678 - val_loss: 0.1113 - val_accuracy: 0.9676\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 66us/sample - loss: 0.1039 - accuracy: 0.9689 - val_loss: 0.1017 - val_accuracy: 0.9697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjGLznhYi1sA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# TBD: shall we delete this block? It seems like this block does not mean much \n",
        "#      for our demo here?\n",
        "\n",
        "\n",
        "# Evaluate the network\n",
        "print('Evaluate on test data:')\n",
        "results = model_1.evaluate(x_test, y_test, batch_size=128)\n",
        "print('Test loss = {0}, Test acc: {1}'.format(results[0], results[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OJp4So9bYYR",
        "colab_type": "text"
      },
      "source": [
        "# Comparision with the Performance of SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug0ug4A240T5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(\n",
        "        64, input_shape=(784, ), activation='relu', name='dense_1'),\n",
        "    tf.keras.layers.Dense(64, activation='relu', name='dense_2'),\n",
        "    tf.keras.layers.Dense(10, activation='softmax', name='predictions'),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8QC3xCwbfNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SGD_frobenius_norm_of_weight = []\n",
        "SGD_get_weight_norm = tf.keras.callbacks.LambdaCallback(\n",
        "    on_epoch_end=lambda batch, logs: SGD_frobenius_norm_of_weight.append(\n",
        "        frobenius_norm(model_2.trainable_weights).numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BNi4yXGcDlg",
        "colab_type": "code",
        "outputId": "ee47c20e-7fbc-4cdb-e1de-b852cd7b84b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "# Compile the model\n",
        "\n",
        "model_2.compile(\n",
        "    optimizer=tf.keras.optimizers.SGD(0.1),  # Utilize TFA optimizer\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "history_2 = model_2.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(x_test, y_test),\n",
        "    epochs=epochs,\n",
        "    callbacks=[SGD_get_weight_norm])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 4s 62us/sample - loss: 0.3736 - accuracy: 0.8889 - val_loss: 0.2004 - val_accuracy: 0.9391\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.1726 - accuracy: 0.9490 - val_loss: 0.1667 - val_accuracy: 0.9478\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.1264 - accuracy: 0.9627 - val_loss: 0.1151 - val_accuracy: 0.9647\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0995 - accuracy: 0.9699 - val_loss: 0.1066 - val_accuracy: 0.9669\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0838 - accuracy: 0.9740 - val_loss: 0.0927 - val_accuracy: 0.9694\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0724 - accuracy: 0.9776 - val_loss: 0.0924 - val_accuracy: 0.9714\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0632 - accuracy: 0.9809 - val_loss: 0.0965 - val_accuracy: 0.9686\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 3s 57us/sample - loss: 0.0560 - accuracy: 0.9824 - val_loss: 0.0816 - val_accuracy: 0.9749\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0505 - accuracy: 0.9841 - val_loss: 0.0932 - val_accuracy: 0.9712\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.0440 - accuracy: 0.9865 - val_loss: 0.0907 - val_accuracy: 0.9728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JVE2tSKcIiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TBD: shall we delete this block? It seems like this block does not mean much \n",
        "#      for our demo here?\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate the network\n",
        "print('Evaluate on test data:')\n",
        "results = model_2.evaluate(x_test, y_test, batch_size=128)\n",
        "print('Test loss = {0}, Test acc: {1}'.format(results[0], results[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Myw0FVcd_Z9",
        "colab_type": "text"
      },
      "source": [
        "# Plot the Comparison Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewf17MW1cJVI",
        "colab_type": "code",
        "outputId": "fc955418-a896-402b-e194-98e8dddf5a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "plt.plot(\n",
        "    CG_frobenius_norm_of_weight,\n",
        "    color='r',\n",
        "    label='CG_frobenius_norm_of_weights')\n",
        "plt.plot(\n",
        "    SGD_frobenius_norm_of_weight,\n",
        "    color='b',\n",
        "    label='SGD_frobenius_norm_of_weights')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Frobenius norm of weights')\n",
        "plt.legend(loc=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f54910f1d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}